"""
Agente de Valida√ß√£o e Quantifica√ß√£o de Incerteza.

Respons√°vel por avaliar a confiabilidade das predi√ß√µes do SentimentAgent,
detectar casos amb√≠guos e recomendar interven√ß√£o humana quando necess√°rio.

Fundamenta√ß√£o Te√≥rica:
    Este agente implementa conceitos fundamentais de racioc√≠nio probabil√≠stico
    e quantifica√ß√£o da incerteza, alinhados com a ementa do curso de 
    Introdu√ß√£o √† Intelig√™ncia Artificial. A separa√ß√£o entre classifica√ß√£o
    (SentimentAgent) e valida√ß√£o (ValidationAgent) justifica a arquitetura
    multi-agente, onde agentes especializados colaboram em diferentes
    aspectos do problema.
"""

import numpy as np
from typing import Dict, Any, Tuple, List
from scipy.stats import entropy


class ValidationAgent:
    """
    Agente especializado em quantifica√ß√£o de incerteza e valida√ß√£o de predi√ß√µes.
    
    Implementa t√©cnicas de:
    - An√°lise de confian√ßa probabil√≠stica
    - C√°lculo de entropia para detec√ß√£o de ambiguidade
    - Detec√ß√£o de anomalias (Out-of-Distribution)
    - Recomenda√ß√£o de revis√£o humana (Human-in-the-Loop)
    
    Atributos:
        CONFIDENCE_THRESHOLD_HIGH (float): Limiar para alta confian√ßa (75%)
        CONFIDENCE_THRESHOLD_LOW (float): Limiar para baixa confian√ßa (50%)
        ENTROPY_THRESHOLD (float): Limiar de entropia para ambiguidade
        MIN_TEXT_LENGTH (int): Tamanho m√≠nimo de texto esperado
        MAX_TEXT_LENGTH (int): Tamanho m√°ximo de texto esperado
    
    Fundamenta√ß√£o:
        A entropia de Shannon √© usada como medida de incerteza:
        H(X) = -Œ£ p(x) * log‚ÇÇ(p(x))
        
        Quanto maior a entropia, maior a incerteza do modelo sobre a classifica√ß√£o.
        Para 3 classes com distribui√ß√£o uniforme, H_max = log‚ÇÇ(3) ‚âà 1.58 bits.
    """
    
    # Thresholds calibrados para o dom√≠nio de an√°lise de sentimentos
    CONFIDENCE_THRESHOLD_HIGH = 0.65   # Alta confian√ßa (reduzido para ser menos rigoroso)
    CONFIDENCE_THRESHOLD_LOW = 0.45    # Baixa confian√ßa
    ENTROPY_THRESHOLD = 1.35           # ~85% da entropia m√°xima para 3 classes
    MIN_TEXT_LENGTH = 3                # Palavras m√≠nimas
    MAX_TEXT_LENGTH = 500              # Palavras m√°ximas
    
    def __init__(self):
        """
        Inicializa o agente de valida√ß√£o.
        
        Mant√©m hist√≥rico de valida√ß√µes para an√°lise posterior de calibra√ß√£o.
        """
        self.validation_history: List[Dict[str, Any]] = []
        self.labels = ["Negativo", "Neutro", "Positivo"]
    
    def validate(
        self, 
        text: str, 
        sentiment_result: Dict[str, Any],
        model_type: str = "lr"
    ) -> Dict[str, Any]:
        """
        Valida a predi√ß√£o do SentimentAgent e quantifica incerteza.
        
        Realiza an√°lise multi-dimensional da confiabilidade:
        1. Confian√ßa: Probabilidade m√°xima da classe predita
        2. Entropia: Medida de dispers√£o das probabilidades
        3. An√°lise textual: Detecta textos at√≠picos (OOD)
        4. Spread: Diferen√ßa entre maior e menor probabilidade
        
        Args:
            text: Texto original da avalia√ß√£o
            sentiment_result: Resultado do SentimentAgent contendo:
                - label: Classe predita
                - probabilities: Dict com probabilidades por classe
            model_type: Tipo de modelo usado ("nb" ou "lr")
            
        Returns:
            Dict contendo:
                - status: CONFIAVEL, CONFIANCA_MODERADA, BAIXA_CONFIANCA, AMBIGUO, OOD
                - confianca: Probabilidade m√°xima (0-1)
                - entropia: Medida de incerteza em bits
                - requer_revisao_humana: Boolean indicando necessidade de interven√ß√£o
                - recomendacao: String com a√ß√£o sugerida
                - detalhes: String formatada com an√°lise completa
                - metricas: Dict com m√©tricas num√©ricas
        """
        probabilities = sentiment_result["probabilities"]
        predicted_label = sentiment_result["label"]
        
        # 1. Extrair probabilidade m√°xima (confian√ßa)
        max_prob = max(probabilities.values())
        
        # 2. Calcular entropia de Shannon (incerteza)
        probs_array = np.array(list(probabilities.values()))
        # Adicionar pequeno epsilon para evitar log(0)
        probs_safe = np.clip(probs_array, 1e-10, 1.0)
        entropy_value = entropy(probs_safe, base=2)  # Em bits
        
        # Normalizar entropia (0-1) onde 1 = m√°xima incerteza
        max_entropy = np.log2(len(probabilities))  # log‚ÇÇ(3) ‚âà 1.58 para 3 classes
        normalized_entropy = entropy_value / max_entropy
        
        # 3. An√°lise de caracter√≠sticas do texto (OOD simples)
        text_length = len(text.split())
        is_text_anomaly = (
            text_length < self.MIN_TEXT_LENGTH or 
            text_length > self.MAX_TEXT_LENGTH
        )
        
        # 4. Calcular spread de probabilidades (discriminabilidade)
        prob_spread = max(probabilities.values()) - min(probabilities.values())
        
        # 5. Determinar status e recomenda√ß√£o
        status, recommendation, requires_review = self._determine_status(
            max_prob, entropy_value, is_text_anomaly, prob_spread, text_length
        )
        
        # 6. Gerar explica√ß√£o detalhada
        details = self._generate_details(
            max_prob, entropy_value, normalized_entropy, text_length,
            prob_spread, probabilities, predicted_label, status
        )
        
        # 7. Armazenar no hist√≥rico para an√°lise de calibra√ß√£o
        validation_record = {
            "text_length": text_length,
            "confidence": max_prob,
            "entropy": entropy_value,
            "normalized_entropy": normalized_entropy,
            "status": status,
            "predicted_label": predicted_label,
            "model": model_type,
            "requires_review": requires_review
        }
        self.validation_history.append(validation_record)
        
        return {
            "status": status,
            "confianca": max_prob,
            "entropia": entropy_value,
            "entropia_normalizada": normalized_entropy,
            "requer_revisao_humana": requires_review,
            "recomendacao": recommendation,
            "detalhes": details,
            "metricas": {
                "tamanho_texto": text_length,
                "spread_probabilidades": prob_spread,
                "modelo": model_type,
                "entropia_maxima": max_entropy
            }
        }
    
    def _determine_status(
        self, 
        confidence: float, 
        entropy_val: float, 
        is_anomaly: bool,
        prob_spread: float,
        text_length: int
    ) -> Tuple[str, str, bool]:
        """
        Determina o status de valida√ß√£o baseado em m√∫ltiplos crit√©rios.
        
        Hierarquia de decis√£o:
        1. OOD (Out-of-Distribution) - Texto muito curto ou longo
        2. AMBIGUO - Alta entropia indica incerteza do modelo
        3. BAIXA_CONFIANCA - Probabilidade m√°xima insuficiente
        4. CONFIANCA_MODERADA - Confian√ßa aceit√°vel mas n√£o ideal
        5. CONFIAVEL - Alta confian√ßa, pode prosseguir automaticamente
        
        Args:
            confidence: Probabilidade m√°xima
            entropy_val: Entropia em bits
            is_anomaly: Se texto √© at√≠pico
            prob_spread: Diferen√ßa max-min de probabilidades
            text_length: N√∫mero de palavras
            
        Returns:
            Tuple (status, recomendacao, requer_revisao)
        """
        # 1. Detec√ß√£o de Out-of-Distribution
        if is_anomaly:
            if text_length < self.MIN_TEXT_LENGTH:
                return (
                    "OOD",
                    f"Texto muito curto ({text_length} palavras). Insuficiente para an√°lise confi√°vel.",
                    True
                )
            else:
                return (
                    "OOD", 
                    f"Texto muito longo ({text_length} palavras). Pode conter m√∫ltiplos sentimentos.",
                    True
                )
        
        # 2. Alta Entropia = Ambiguidade (modelo indeciso)
        if entropy_val > self.ENTROPY_THRESHOLD:
            return (
                "AMBIGUO",
                "Sentimento misto ou indefinido detectado. Probabilidades distribu√≠das entre classes.",
                True
            )
        
        # 3. Baixa Confian√ßa
        if confidence < self.CONFIDENCE_THRESHOLD_LOW:
            return (
                "BAIXA_CONFIANCA",
                "Confian√ßa insuficiente na predi√ß√£o. Recomenda-se revis√£o por especialista.",
                True
            )
        
        # 4. Confian√ßa Moderada
        if confidence < self.CONFIDENCE_THRESHOLD_HIGH:
            return (
                "CONFIANCA_MODERADA",
                "Predi√ß√£o aceit√°vel com margem de incerteza. Monitorar resultado.",
                False
            )
        
        # 5. Alta Confian√ßa
        return (
            "CONFIAVEL",
            "Predi√ß√£o altamente confi√°vel. Sistema pode prosseguir automaticamente.",
            False
        )
    
    def _generate_details(
        self, 
        confidence: float, 
        entropy_val: float,
        normalized_entropy: float,
        text_length: int,
        prob_spread: float,
        probabilities: Dict[str, float],
        predicted_label: str,
        status: str
    ) -> str:
        """
        Gera explica√ß√£o textual detalhada da an√°lise de valida√ß√£o.
        
        Formata as m√©tricas e interpreta√ß√µes de forma leg√≠vel para
        apresenta√ß√£o na interface e relat√≥rios.
        """
        lines = [
            "üìä **M√©tricas de Confiabilidade:**",
            f"‚Ä¢ Confian√ßa: **{confidence:.1%}** (prob. da classe predita)",
            f"‚Ä¢ Entropia: **{entropy_val:.3f}** bits ({normalized_entropy:.1%} da m√°xima)",
            f"‚Ä¢ Spread: **{prob_spread:.3f}** (discriminabilidade)",
            f"‚Ä¢ Tamanho: **{text_length}** palavras",
            "",
            "üéØ **Distribui√ß√£o de Probabilidades:**"
        ]
        
        # Ordenar probabilidades do maior para menor
        sorted_probs = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)
        for label, prob in sorted_probs:
            marker = "‚Üí" if label == predicted_label else " "
            bar_length = int(prob * 20)
            bar = "‚ñà" * bar_length + "‚ñë" * (20 - bar_length)
            lines.append(f"{marker} {label}: {bar} {prob:.1%}")
        
        # Interpreta√ß√£o baseada no status
        lines.append("")
        lines.append("üí° **Interpreta√ß√£o:**")
        
        interpretations = {
            "CONFIAVEL": "‚úÖ Modelo altamente confiante. Distribui√ß√£o de probabilidades bem definida.",
            "CONFIANCA_MODERADA": "‚ö†Ô∏è Confian√ßa aceit√°vel, mas existe incerteza residual entre classes.",
            "BAIXA_CONFIANCA": "‚ùå Modelo inseguro. Probabilidades pr√≥ximas entre classes.",
            "AMBIGUO": "üîÄ Alta entropia indica poss√≠vel sentimento misto ou texto amb√≠guo.",
            "OOD": "‚ö° Texto fora do padr√£o de treinamento. Resultados podem n√£o ser confi√°veis."
        }
        lines.append(interpretations.get(status, "Status desconhecido."))
        
        return "\n".join(lines)
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        Retorna estat√≠sticas agregadas do hist√≥rico de valida√ß√µes.
        
        √ötil para:
        - An√°lise de calibra√ß√£o do modelo em produ√ß√£o
        - Identifica√ß√£o de padr√µes de incerteza
        - Monitoramento de taxa de revis√£o humana
        
        Returns:
            Dict com estat√≠sticas agregadas ou mensagem de erro
        """
        if not self.validation_history:
            return {"message": "Nenhuma valida√ß√£o realizada ainda."}
        
        confidences = [v["confidence"] for v in self.validation_history]
        entropies = [v["entropy"] for v in self.validation_history]
        statuses = [v["status"] for v in self.validation_history]
        
        # Calcular distribui√ß√£o de status
        status_counts = {}
        for status in set(statuses):
            status_counts[status] = statuses.count(status)
        
        # Taxa de revis√£o humana
        reviews_needed = sum(1 for v in self.validation_history if v["requires_review"])
        review_rate = reviews_needed / len(self.validation_history)
        
        return {
            "total_validacoes": len(self.validation_history),
            "confianca": {
                "media": float(np.mean(confidences)),
                "std": float(np.std(confidences)),
                "min": float(np.min(confidences)),
                "max": float(np.max(confidences))
            },
            "entropia": {
                "media": float(np.mean(entropies)),
                "std": float(np.std(entropies))
            },
            "distribuicao_status": status_counts,
            "taxa_revisao_humana": review_rate,
            "total_revisoes_necessarias": reviews_needed
        }
    
    def reset_history(self) -> None:
        """Limpa o hist√≥rico de valida√ß√µes."""
        self.validation_history = []
